# ğŸ¨ Visual Architecture Guide: Protein Ensemble VAE

**Companion to**: TECHNICAL_DEEP_DIVE.md  
**Purpose**: Visual diagrams showing information flow and tensor shapes

---

## ğŸ“Š FIGURE 1: Complete Architecture Overview

```
INPUT LAYER                                                    BATCH Ã— LENGTH Ã— DIM
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ESM-2 Embeddings        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             [B, L, 1280]
(from pretrained model) â”‚ A: 1.2, -0.8, 0.3... â”‚
                        â”‚ L: 0.9,  0.5, -1.1...â”‚
                        â”‚ K: ...               â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
N Coordinates          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              [B, L, 3]
(Nitrogen backbone)     â”‚ [xâ‚, yâ‚, zâ‚]         â”‚
                        â”‚ [xâ‚‚, yâ‚‚, zâ‚‚]         â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
CA Coordinates         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              [B, L, 3]
(Alpha carbon)          â”‚ [xâ‚, yâ‚, zâ‚]         â”‚
                        â”‚ [xâ‚‚, yâ‚‚, zâ‚‚]         â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
C Coordinates          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              [B, L, 3]
(Carbonyl carbon)       â”‚ [xâ‚, yâ‚, zâ‚]         â”‚
                        â”‚ [xâ‚‚, yâ‚‚, zâ‚‚]         â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
Dihedral Angles        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              [B, L, 6]
(Ï†, Ïˆ, Ï‰ as sin/cos)    â”‚ [sin Ï†, cos Ï†,       â”‚
                        â”‚  sin Ïˆ, cos Ïˆ,       â”‚
                        â”‚  sin Ï‰, cos Ï‰]       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
Valid Residue Mask     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              [B, L]
                        â”‚ [1, 1, 1, ..., 0, 0] â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                 â†“â†“â†“

ENCODER (Multi-Modal Fusion)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚            â”‚            â”‚
                    â†“            â†“            â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ seq_proj        â”‚ â”‚coord_projâ”‚ â”‚ dih_proj â”‚         [B, L, 256]
        â”‚ Linear(1280â†’256)â”‚ â”‚Linear(9â†’128)â”‚Linear(6â†’128)â”‚     [B, L, 128]
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         [B, L, 128]
                    â”‚            â”‚            â”‚
                    â”‚            â†“            â†“
                    â”‚      LayerNorm     LayerNorm
                    â”‚            â”‚            â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                         concat(seq, coord, dih)              [B, L, 512]
                                 â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ feature_fusionâ”‚
                          â”‚ MLP + LayerNormâ”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    [B, L, 512]
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                          â”‚
            SinusoidalPE                GeometricAttention
            (positional)                 (local structure)
                    â”‚                          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                         H = features + 0.1 * attn            [B, L, 512]
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Transformer Layers    â”‚
                    â”‚   (6 layers, 8 heads)   â”‚
                    â”‚   Self-attention +      â”‚
                    â”‚   Feed-forward          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              [B, L, 512]
                                 â”‚
                          encoded_features                    [B, L, 512]
                                 â”‚
                                 â†“â†“â†“

LATENT SPACE (Hierarchical)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                          â”‚
            GLOBAL LATENT               LOCAL LATENT
            â•â•â•â•â•â•â•â•â•â•â•â•â•               â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    â”‚                          â”‚
           mean(encoded, dim=1)        per-residue features
                    â”‚                          â”‚
                    â†“                          â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Î¼_global, ÏƒÂ²_global â”‚    â”‚  Î¼_local, ÏƒÂ²_localâ”‚
        â”‚   [B, 512], [B, 512]  â”‚    â”‚  [B,L,256],[B,L,256]â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                          â”‚
                    â†“                          â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  z_g = Î¼ + ÎµÂ·Ïƒ         â”‚    â”‚  z_l = Î¼ + ÎµÂ·Ïƒ    â”‚
        â”‚  Îµ ~ N(0,I)           â”‚    â”‚  Îµ ~ N(0,I)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                     z_g, z_l (sampled latents)
                                 â”‚
                                 â†“â†“â†“

DECODER (E(n)-Equivariant)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Expand z_g to [B,L,512] â”‚
                    â”‚ Concat with z_l         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                         z_combined = [z_g; z_l]              [B, L, 768]
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                          â”‚
              STRUCTURE PATHWAY        SEQUENCE PATHWAY
              â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    â”‚                          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
    â”‚ latent_to_coords         â”‚              â”‚
    â”‚ MLP(768 â†’ 3)             â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                    â”‚                          â”‚
         x_CA (initialized)   [B,L,3]         â”‚
                    â”‚                          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
    â”‚ input_embedding          â”‚              â”‚
    â”‚ Linear(768 â†’ 256)        â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                    â”‚                          â”‚
           h (node features)    [B,L,256]     â”‚
                    â”‚                          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
    â”‚ build_edge_index(k=20)   â”‚              â”‚
    â”‚ k-NN connectivity        â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                    â”‚                          â”‚
          edge_index [2, E]                    â”‚
                    â”‚                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
          â”‚  EGNN Layers (8x) â”‚                â”‚
          â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚                â”‚
          â”‚  for layer in     â”‚                â”‚
          â”‚    layers:        â”‚                â”‚
          â”‚      m_ij = Ï†_e(  â”‚                â”‚
          â”‚        [h[i],     â”‚                â”‚
          â”‚         h[j],     â”‚                â”‚
          â”‚         ||x_i-x_j||Â²]â”‚              â”‚
          â”‚      )            â”‚                â”‚
          â”‚      h[i] += Ï†_h( â”‚                â”‚
          â”‚        [h[i],     â”‚                â”‚
          â”‚         Î£ m_ij]   â”‚                â”‚
          â”‚      )            â”‚                â”‚
          â”‚      w_ij = Ï†_x(m_ij)â”‚              â”‚
          â”‚      x_CA[i] +=   â”‚                â”‚
          â”‚        Î£ w_ijÂ·    â”‚                â”‚
          â”‚          (x_i-x_j)â”‚                â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
                    â”‚                          â”‚
        h (refined), x_CA (refined)            â”‚
                    â”‚                          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
    â”‚ n_offset_head            â”‚              â”‚
    â”‚ MLP(256 â†’ 3)             â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                    â”‚                          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
    â”‚ PROJECT to bond length    â”‚              â”‚
    â”‚ n_offset = normalize() *  â”‚              â”‚
    â”‚            1.46 Ã…         â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                    â”‚                          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
    â”‚ c_offset_head            â”‚              â”‚
    â”‚ MLP(256 â†’ 3)             â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                    â”‚                          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
    â”‚ PROJECT to bond length    â”‚              â”‚
    â”‚ c_offset = normalize() *  â”‚              â”‚
    â”‚            1.52 Ã…         â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                    â”‚                          â”‚
         x_N = x_CA + n_offset [B,L,3]        â”‚
         x_C = x_CA + c_offset [B,L,3]        â”‚
                    â”‚                          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
    â”‚ CONSTRAIN peptide bonds   â”‚              â”‚
    â”‚ for i in range(L-1):      â”‚              â”‚
    â”‚   vec = x_N[i+1] - x_C[i] â”‚              â”‚
    â”‚   x_N[i+1] = x_C[i] +     â”‚              â”‚
    â”‚     normalize(vec) * 1.33 â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                    â”‚                          â”‚
                    â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚              â”‚ sequence_head_direct â”‚
                    â”‚              â”‚ MLP(768 â†’ 20)        â”‚
                    â”‚              â”‚ (bypasses EGNN!)     â”‚
                    â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                          â”‚
                    â”‚                          â”‚
                    â†“                          â†“
            x_N, x_CA, x_C               seq_logits
            [B, L, 3] each               [B, L, 20]

OUTPUT LAYER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    Predicted Structure:
        N  coordinates: [B, L, 3]  (nitrogen)
        CA coordinates: [B, L, 3]  (alpha carbon)
        C  coordinates: [B, L, 3]  (carbonyl carbon)
    
    Predicted Sequence:
        AA logits: [B, L, 20]  (amino acid probabilities)
    
    Latent Parameters (for loss):
        Î¼_g, log_ÏƒÂ²_g: [B, 512]      (global)
        Î¼_l, log_ÏƒÂ²_l: [B, L, 256]   (local)
```

---

## ğŸ“Š FIGURE 2: EGNN Layer Details

```
EGNN Layer: E(n)-Equivariant Message Passing
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

INPUT:
    h: [N, node_dim]    (node features)
    x: [N, 3]           (coordinates)
    edges: [2, E]       (connectivity)

STEP 1: Compute Relative Positions
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    For each edge (i, j):
        rel_ij = x[i] - x[j]                    [E, 3]
        dÂ²_ij = ||rel_ij||Â²                     [E, 1]
    
    Visualization:
        o x[i]
         \
          \ rel_ij
           \
            o x[j]

STEP 2: Edge Messages
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    m_ij = MLP([h[i], h[j], dÂ²_ij])           [E, hidden_dim]
    
    MLP structure:
        Linear(2Â·node_dim + 1 â†’ hidden_dim)
        SiLU()
        Linear(hidden_dim â†’ hidden_dim)
        SiLU()

STEP 3: Aggregate Messages
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    For each node i:
        agg[i] = Î£_{jâˆˆneighbors(i)} m_ij       [N, hidden_dim]
    
    Visualization:
           m_12 â”€â”€â”
           m_13 â”€â”€â”¤
           m_14 â”€â”€â”¼â”€â”€> agg[1]
           m_15 â”€â”€â”˜

STEP 4: Update Node Features
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    h'[i] = h[i] + MLP([h[i], agg[i]])        [N, node_dim]
    h[i] = LayerNorm(h'[i])
    
    Residual connection prevents gradient vanishing!

STEP 5: Coordinate Update (KEY FOR EQUIVARIANCE!)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    w_ij = MLP(m_ij)                           [E, 1] (scalar!)
    
    Î”x[i] = Î£_{jâˆˆneighbors(i)} w_ij Â· rel_ij  [N, 3]
                                    â†‘
                                    scalar Ã— vector
    
    x[i] = x[i] + Î”x[i]
    
    Why this is equivariant:
        Î”x[i] = Î£ w_ij Â· (x[i] - x[j])
              = (Î£ w_ij) Â· x[i] - Î£ w_ij Â· x[j]
              â†‘                    â†‘
              linear combination of input coordinates
              â†’ rotates with input!

MATHEMATICAL PROOF OF EQUIVARIANCE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Let R be a rotation matrix, x' = RÂ·x
    
    Then:
        rel'_ij = x'[i] - x'[j]
                = RÂ·x[i] - RÂ·x[j]
                = RÂ·(x[i] - x[j])
                = RÂ·rel_ij        âœ“
        
        dÂ²'_ij = ||rel'_ij||Â²
               = ||RÂ·rel_ij||Â²
               = ||rel_ij||Â²      âœ“ (rotation preserves norm)
        
        m'_ij = MLP([h[i], h[j], dÂ²'_ij])
              = MLP([h[i], h[j], dÂ²_ij])
              = m_ij              âœ“ (same messages)
        
        Î”x'[i] = Î£ w_ij Â· rel'_ij
               = Î£ w_ij Â· RÂ·rel_ij
               = R Â· Î£ w_ij Â· rel_ij
               = R Â· Î”x[i]        âœ“
        
        x'[i]_new = x'[i] + Î”x'[i]
                  = RÂ·x[i] + RÂ·Î”x[i]
                  = RÂ·(x[i] + Î”x[i])
                  = RÂ·x[i]_new     âœ“âœ“ EQUIVARIANT!

OUTPUT:
    h: [N, node_dim]    (updated features)
    x: [N, 3]           (refined coordinates)
```

---

## ğŸ“Š FIGURE 3: Bond Constraint Enforcement

```
BOND LENGTH PROJECTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROBLEM: MLP outputs arbitrary vectors
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    n_offset_raw = MLP(h)                     [B, L, 3]
    ||n_offset_raw|| = ???  (could be 0.5Ã… or 2.0Ã…)
    
    x_N = x_CA + n_offset_raw
    Bond length = ||x_N - x_CA|| = WRONG!

SOLUTION: Project to exact length
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Step 1: Normalize to unit vector
        n_direction = n_offset_raw / ||n_offset_raw||
        ||n_direction|| = 1.0  âœ“
    
    Step 2: Scale to target length
        n_offset = n_direction * 1.46 Ã…
        ||n_offset|| = 1.46 Ã…  âœ“âœ“
    
    Step 3: Apply offset
        x_N = x_CA + n_offset
        ||x_N - x_CA|| = 1.46 Ã…  âœ“âœ“âœ“ EXACT!

VISUALIZATION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Before projection:
        x_CA o---------> n_offset_raw
             â†‘ length = 1.2Ã… (WRONG!)
    
    After projection:
        x_CA o-------> n_offset
             â†‘ length = 1.46Ã… (CORRECT!)

SAME PROCESS FOR ALL BONDS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    N-CA bond:
        n_offset = normalize(n_offset_raw) * 1.46 Ã…
    
    CA-C bond:
        c_offset = normalize(c_offset_raw) * 1.52 Ã…
    
    C-N peptide bond:
        for i in range(L-1):
            peptide_vec = x_N[i+1] - x_C[i]
            peptide_unit = peptide_vec / ||peptide_vec||
            x_N[i+1] = x_C[i] + peptide_unit * 1.33 Ã…

RESULT:
â”€â”€â”€â”€â”€â”€â”€
    âœ… All bond lengths EXACTLY match chemistry
    âœ… Model learns DIRECTION, we enforce MAGNITUDE
    âœ… No violations in generated structures
```

---

## ğŸ“Š FIGURE 4: Information Flow Analysis

```
WHAT INFORMATION IS PRESERVED WHERE?
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

INPUT STAGE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ESM-2 Embeddings [B, L, 1280]
    â”œâ”€ Chemical properties (hydrophobic, polar, charged)
    â”œâ”€ Evolutionary patterns
    â”œâ”€ Sequence context
    â””â”€ Amino acid identity  â† CRITICAL FOR SEQUENCE!

Coordinates [B, L, 9]
    â”œâ”€ 3D structure
    â”œâ”€ Distance patterns
    â””â”€ Global fold

Dihedrals [B, L, 6]
    â”œâ”€ Backbone flexibility
    â”œâ”€ Local geometry
    â””â”€ Secondary structure

                â†“ PROJECT & FUSE

ENCODER STAGE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Fused features [B, L, 512]
    â”œâ”€ 50% sequence (256D) â† ESM information
    â”œâ”€ 25% geometry (128D)
    â””â”€ 25% dihedrals (128D)

                â†“ TRANSFORMER (6 layers)

Encoded features [B, L, 512]
    â”œâ”€ Long-range interactions
    â”œâ”€ Global context
    â”œâ”€ Mixed modalities
    â””â”€ STILL HAS SEQUENCE INFO âœ“

                â†“ SPLIT

LATENT STAGE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
z_global [B, 512]
    â”œâ”€ Overall fold
    â”œâ”€ Protein class
    â””â”€ Average composition

z_local [B, L, 256]
    â”œâ”€ Per-residue geometry
    â”œâ”€ Local structure
    â””â”€ RESIDUE-SPECIFIC CHEMISTRY âœ“  â† PRESERVED!

                â†“ CONCAT

z_combined [B, L, 768]
    â””â”€ ALL INFORMATION PRESENT âœ“âœ“

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                      â”‚
        â†“                      â†“
    STRUCTURE              SEQUENCE
    PATHWAY               PATHWAY
        â”‚                      â”‚
        â†“ EGNN (8 layers)      â†“ DIRECT MLP
        â”‚                      â”‚
    h_refined              seq_logits
    [B, L, 256]            [B, L, 20]
    â”‚                          â”‚
    â”œâ”€ Geometric info      â”œâ”€ Chemical info âœ“
    â”œâ”€ Distance patterns   â”œâ”€ Sequence patterns âœ“
    â””â”€ Structure only      â””â”€ Direct from z_combined!
    
    âŒ LOST chemical       âœ… PRESERVED chemical
       information!            information!

INFORMATION PRESERVATION ANALYSIS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Structure pathway:
        z_combined â†’ EGNN â†’ h_refined â†’ x_N, x_CA, x_C
                     â†‘
                     Only uses distances and relative positions
                     â†’ DISCARDS amino acid identity!
    
    Sequence pathway (current):
        z_combined â†’ MLP â†’ seq_logits
        â†‘
        Bypass EGNN, directly access z_combined
        â†’ PRESERVES amino acid information âœ“

    Sequence pathway (old, BAD):
        z_combined â†’ EGNN â†’ h_refined â†’ MLP â†’ seq_logits
                             â†‘
                             Chemical info lost here!
                             â†’ Poor sequence recovery (15-25%)

KEY INSIGHT:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    EGNN is GEOMETRICALLY EQUIVARIANT
    â†’ Can't distinguish amino acids with same backbone!
    â†’ Must predict sequence BEFORE EGNN processing!

RESULT:
â”€â”€â”€â”€â”€â”€â”€
    Structure: 0.546Ã… RMSD âœ“
    Sequence:  29.5% recovery (current)
               â†’ 40-45% after Tier 1 fixes âœ“âœ“
```

---

## ğŸ“Š FIGURE 5: Loss Function Interactions

```
TRAINING DYNAMICS: How Losses Interact
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RECONSTRUCTION LOSSES (Drive learning):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    L_rmsd = ||pred_coords - true_coords||Â²     weight: 50.0
    L_pair = |dist(pred) - dist(true)|          weight: 30.0
    
    Combined effect:
        â”œâ”€ L_rmsd: Local accuracy (each atom close)
        â””â”€ L_pair: Global structure (relative distances)
        
        Optimization landscape:
            High L_rmsd, High L_pair â†’ Far from solution
            Low L_rmsd, High L_pair  â†’ Stretched/compressed
            High L_rmsd, Low L_pair  â†’ Local errors
            Low L_rmsd, Low L_pair   â†’ GOOD! âœ“

REGULARIZATION LOSSES (Prevent overfitting):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    L_kl_global = KL(q(z_g|x) || N(0,I))        weight: 0.5
    L_kl_local  = KL(q(z_l|x) || N(0,I))        weight: 0.1
    
    Effect on latent space:
        No KL:          Latent space is sparse and irregular
                        â–ˆâ–ˆâ–ˆâ–ˆ    â–ˆ   â–ˆâ–ˆ     â–ˆ
                        â†’ Sampling fails, no interpolation
        
        Optimal KL:     Latent space is dense and smooth
                        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                        â†’ Sampling works, interpolation smooth
        
        Too much KL:    Posterior collapse
                        â–ˆ
                        â†’ Model ignores latents, uses decoder only

GEOMETRY LOSSES (Enforce physics):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    L_rama       = penalty(Ï†, Ïˆ in forbidden)   weight: 5.0
    L_bond       = |length - target|            weight: 200.0 â†’ 400.0
    L_angle      = |angle - target|             weight: 30.0 â†’ 100.0
    L_dihedral   = |dih_pred - dih_true|        weight: 0.5
    
    Interaction diagram:
        
        L_reconstruction â”€â”€â”€â”¬â”€â†’ Minimize coordinate error
                            â”‚
        L_bond â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â†’ Constrain N-CA, CA-C, C-N lengths
                            â”‚
        L_angle â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â†’ Constrain N-CA-C, CA-C-N, C-N-CA angles
                            â”‚
        L_rama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â†’ Avoid forbidden (Ï†, Ïˆ) regions
                            â”‚
        L_dihedral â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â†’ Match target angles
        
        These compete!
            Low L_reconstruction â†’ pred close to target
            High L_bond/angle    â†’ target might violate geometry!
        
        Solution: Target geometries are from PDB â†’ already valid!
                  â†’ Losses align, no conflict âœ“

SEQUENCE LOSS (Predict amino acids):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    L_seq = -Î£ log p(aa[i] | z)                 weight: 20.0 â†’ 80.0
    
    Trade-off with structure:
        
        Shared latent (current):
            z â†’ structure loss (dominates, weight: 50.0)
            z â†’ sequence loss (weak, weight: 20.0)
            
            Result: z encodes mostly structure
                    â†’ Poor sequence recovery
        
        Increased weight (Tier 1):
            z â†’ structure loss (weight: 50.0)
            z â†’ sequence loss (weight: 80.0)
            
            Result: z must encode BOTH
                    â†’ Better sequence recovery âœ“

CYCLICAL KL ANNEALING:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Cycle 1:  KL: 0 â†’ 1    Learn approximate structure
    Cycle 2:  KL: 0 â†’ 1    Refine, add details
    Cycle 3:  KL: 0 â†’ 1    Polish, smooth latent space
    Cycle 4:  KL: 0 â†’ 1    Final optimization
    
    Why cycles help:
        Monotonic (0â†’1 once):
            Early: Low KL â†’ free exploration
            Late:  High KL â†’ stuck in local minimum
        
        Cyclical (0â†’1 repeated):
            Each cycle: Fresh start â†’ escape local minima
            Multiple chances to learn â†’ better final result

TOTAL LOSS BALANCE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    total_loss = 50.0  * L_rmsd         (Primary driver)
               + 30.0  * L_pair         (Global structure)
               + 0.5   * L_kl_global    (Regularization)
               + 0.1   * L_kl_local     (Light regularization)
               + 5.0   * L_rama         (Physics: Ramachandran)
               + 400.0 * L_bond         (Physics: Bond lengths) â† INCREASE
               + 100.0 * L_angle        (Physics: Bond angles)  â† INCREASE
               + 0.5   * L_dihedral     (Consistency)
               + 80.0  * L_seq          (Sequence prediction)   â† INCREASE
    
    Relative importance:
        Bond constraints: 400.0  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
        Bond angles:      100.0  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
        Sequence:          80.0  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
        Reconstruction:    50.0  â–ˆâ–ˆâ–ˆâ–ˆ
        Pair distance:     30.0  â–ˆâ–ˆ
        Ramachandran:       5.0  â–Œ
        KL global:          0.5  
        Dihedral:           0.5  
        KL local:           0.1  
```

---

## ğŸ“Š FIGURE 6: Latent Space Geometry

```
HIERARCHICAL LATENT SPACE VISUALIZATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

GLOBAL LATENT (z_global): [B, 512]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Conceptual structure (learned implicitly):
        
        z_g[0:128]:   Fold topology
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Î±-helical bundle        â”‚
                      â”‚ Î²-barrel                â”‚
                      â”‚ Î±+Î² mixed               â”‚
                      â”‚ Î±/Î² TIM barrel          â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        z_g[128:256]: Size & compactness
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Radius of gyration      â”‚
                      â”‚ Number of residues      â”‚
                      â”‚ Domain count            â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        z_g[256:384]: Secondary structure content
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ % Î±-helix               â”‚
                      â”‚ % Î²-sheet               â”‚
                      â”‚ % loop/coil             â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        z_g[384:512]: Sequence properties
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Hydrophobic %           â”‚
                      â”‚ Charged %               â”‚
                      â”‚ Aromatic %              â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LOCAL LATENT (z_local): [B, L, 256]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    For each residue i:
        
        z_l[i, 0:64]:   Backbone geometry
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ Ï† angle             â”‚
                        â”‚ Ïˆ angle             â”‚
                        â”‚ Ï‰ angle             â”‚
                        â”‚ Local curvature     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        z_l[i, 64:128]: Secondary structure
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ Helix probability   â”‚
                        â”‚ Sheet probability   â”‚
                        â”‚ Loop probability    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        z_l[i, 128:192]: Side-chain info
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ Ï‡1 angle (rotamer)  â”‚
                        â”‚ Solvent exposure    â”‚
                        â”‚ Packing density     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        z_l[i, 192:256]: Chemical properties
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ Hydrophobicity      â”‚
                        â”‚ Charge              â”‚
                        â”‚ Size                â”‚
                        â”‚ Aromaticity         â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LATENT SPACE SMOOTHNESS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Good VAE (after training with optimal KL):
        
        Protein A â—â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â— Protein B
                  â†‘      â†‘      â†‘
                  z1     z_mid  z2
        
        z_mid = 0.5 * (z1 + z2)
        â†’ Valid intermediate conformation âœ“
    
    Poor VAE (posterior collapse or too much KL):
        
        Protein A â—            â— Protein B
                      âœ—
                    (void)
        
        z_mid = 0.5 * (z1 + z2)
        â†’ Invalid structure (steric clashes) âœ—

CAPACITY ANALYSIS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Total parameters:
        Global: 512 dims
        Local:  256 dims Ã— L residues
        
        For L=100: 512 + 256*100 = 26,112 parameters
        For L=200: 512 + 256*200 = 51,712 parameters
    
    Information content (bits):
        Assuming each dim ~ 8 bits effective precision:
            Global: 512 * 8 = 4,096 bits
            Local:  256 * 100 * 8 = 204,800 bits
            Total:  208,896 bits = 26.1 KB
        
        Compare to raw coordinates:
            3 atoms Ã— L residues Ã— 3 coords Ã— 32 bits
            = 9 * 100 * 32 = 28,800 bits = 3.6 KB
        
        Your model uses 7Ã— more capacity!
        â†’ Can store additional information beyond coordinates
           (sequence, dynamics, uncertainty, etc.)

WHY HIERARCHICAL BEATS FLAT:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    Flat latent (BAD):
        z_flat = [z1, z2, ..., z512]
        
        Problems:
            âŒ Must encode BOTH global AND local in same space
            âŒ Information competition â†’ latent units fight
            âŒ Posterior collapse more likely
            âŒ Hard to control generation
        
        Example failure:
            Want to change: Loop conformation (local)
            Keep same:      Overall fold (global)
            
            â†’ IMPOSSIBLE with flat latent!
               Changing z affects EVERYTHING
    
    Hierarchical (GOOD):
        z_global + z_local
        
        Benefits:
            âœ… Separation of concerns â†’ no competition
            âœ… Both latents used â†’ no collapse
            âœ… Controllable generation:
               - Fix z_g, vary z_l â†’ same fold, different loops
               - Vary z_g, fix z_l â†’ different fold, same local geometry
            âœ… More interpretable â†’ can analyze separately
```

---

## ğŸ“Š FIGURE 7: Training Progression

```
TYPICAL TRAINING TRAJECTORY (100 epochs, 4 KL cycles)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

METRICS OVER TIME:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Reconstruction RMSD (Ã…):
    10.0 |âœ—
         |  âœ—
     5.0 |    âœ—âœ—
         |       âœ—âœ—âœ—
     1.0 |           âœ—âœ—âœ—âœ—âœ—
         |                 âœ—âœ—âœ—âœ—âœ—âœ—âœ—âœ—
     0.5 |                         âœ—âœ—âœ—âœ—âœ—âœ—âœ—âœ—âœ—âœ—
         |                                     âœ—âœ—âœ—âœ—âœ—âœ—âœ—âœ—
     0.0 +â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Epoch
         0        25        50        75        100

KL Divergence:
     2.0 |    â•±â•²        â•±â•²        â•±â•²        â•±â•²
         |   â•±  â•²      â•±  â•²      â•±  â•²      â•±  â•²
     1.0 |  â•±    â•²    â•±    â•²    â•±    â•²    â•±    â•²
         | â•±      â•²  â•±      â•²  â•±      â•²  â•±      â•²
     0.0 |â•±        â•²â•±        â•²â•±        â•²â•±        â•²
         +â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Epoch
         0        25        50        75        100
         â””â”€Cycle 1â”€â”˜â””â”€Cycle 2â”€â”˜â””â”€Cycle 3â”€â”˜â””â”€Cycle 4â”€â”˜

Sequence Recovery (%):
     40% |                                     âœ—âœ—âœ—âœ—âœ—âœ—âœ—âœ—
         |                               âœ—âœ—âœ—âœ—
     30% |                         âœ—âœ—âœ—âœ—
         |                   âœ—âœ—âœ—âœ—
     20% |             âœ—âœ—âœ—âœ—
         |       âœ—âœ—âœ—âœ—
     10% | âœ—âœ—âœ—âœ—
         +â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Epoch
         0        25        50        75        100

Ramachandran Outliers (%):
     30% |âœ—âœ—
         |  âœ—âœ—
     20% |    âœ—âœ—
         |      âœ—âœ—
     10% |        âœ—âœ—âœ—âœ—
         |            âœ—âœ—âœ—âœ—âœ—âœ—
      5% |                  âœ—âœ—âœ—âœ—âœ—âœ—
         |                        âœ—âœ—âœ—âœ—âœ—âœ—âœ—âœ—âœ—âœ—
      0% +â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Epoch
         0        25        50        75        100

WHAT HAPPENS EACH PHASE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Epoch 0-10 (Cycle 1, low KL):
    âœ“ Model learns gross structure
    âœ“ Latent space is flexible
    âœ— High reconstruction error (5-10Ã… RMSD)
    âœ— Many Ramachandran violations (30%)
    âœ— Poor sequence recovery (10%)

Epoch 10-25 (Cycle 1, high KL):
    âœ“ Refines structure
    âœ“ Latent space regularizes
    âœ“ RMSD improves to 2-3Ã…
    âœ“ Ramachandran violations drop to 15%
    âš ï¸  Sequence recovery plateaus at 15%

Epoch 25-50 (Cycle 2):
    âœ“ Re-exploration phase (low KL start)
    âœ“ Escapes local minima
    âœ“ RMSD improves to 1.0-1.5Ã…
    âœ“ Ramachandran violations drop to 5%
    âœ“ Sequence recovery improves to 25%

Epoch 50-75 (Cycle 3):
    âœ“ Fine-tuning phase
    âœ“ RMSD converges to 0.5-0.8Ã…
    âœ“ Ramachandran violations < 2%
    âœ“ Sequence recovery reaches 29-30%

Epoch 75-100 (Cycle 4):
    âœ“ Final polish
    âœ“ All metrics stable
    âœ“ Latent space smooth and dense
    âœ“ Model ready for generation

VALIDATION CURVE (detect overfitting):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Loss:
     |  Train â”€â”€â”€
     |          â•²
     |           â•²___
     |               â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     |                
     |  Valid â”€â”€â”€â”€
     |           â•²
     |            â•²____
     |                 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (plateau, good!)
     |
     +â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Epoch

    No overfitting visible â†’ dataset is generalizable âœ“

LOSS COMPONENT EVOLUTION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Epoch 0:
    Reconstruction: 50.0 * 100.0 = 5000.0  (HUGE!)
    KL global:      0.0  * 5.0   = 0.0     (annealed to 0)
    KL local:       0.0  * 3.0   = 0.0     (annealed to 0)
    Bond:           200.0 * 2.0  = 400.0   (moderate violations)
    Sequence:       20.0 * 2.3   = 46.0    (cross-entropy)
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Total:          5446.0

Epoch 50:
    Reconstruction: 50.0 * 0.5   = 25.0    (good structure!)
    KL global:      0.5  * 2.0   = 1.0     (regularized)
    KL local:       0.1  * 1.5   = 0.15    (regularized)
    Bond:           200.0 * 0.01 = 2.0     (minimal violations)
    Sequence:       20.0 * 1.2   = 24.0    (improving)
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Total:          52.15

Epoch 100:
    Reconstruction: 50.0 * 0.3   = 15.0    (excellent!)
    KL global:      0.5  * 1.2   = 0.6     (optimal)
    KL local:       0.1  * 0.8   = 0.08    (optimal)
    Bond:           400.0 * 0.005= 2.0     (near-perfect!)
    Sequence:       80.0 * 0.9   = 72.0    (much better!)
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Total:          89.68

    Note: Total loss increases slightly because sequence
          weight increased (20â†’80), but all components improve!
```

---

**This visual guide complements the technical deep-dive to give you a complete understanding of the architecture, information flow, and training dynamics! ğŸ¨**

